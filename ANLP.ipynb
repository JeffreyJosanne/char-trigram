{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Small LSTM Network to Generate Text for Alice in Wonderland\n",
    "\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense\n",
    "# from keras.layers import Dropout\n",
    "# from keras.layers import LSTM\n",
    "# from keras.callbacks import ModelCheckpoint\n",
    "# from keras.utils import np_utils\n",
    "# # load ascii text and covert to lowercase\n",
    "# # filename = \"wonderland.txt\"\n",
    "# # raw_text = open(filename).read()\n",
    "# raw_text = list\n",
    "# # create mapping of unique chars to integers\n",
    "# chars = sorted(list(set(raw_text)))\n",
    "# char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "# # summarize the loaded data\n",
    "# n_chars = len(raw_text)\n",
    "# n_vocab = len(chars)\n",
    "# print (\"Total Characters: \", n_chars)\n",
    "# print (\"Total Vocab: \", n_vocab)\n",
    "# # prepare the dataset of input to output pairs encoded as integers\n",
    "# seq_length = 100\n",
    "# dataX = []\n",
    "# dataY = []\n",
    "# for i in range(0, n_chars - seq_length, 1):\n",
    "#     seq_in = raw_text[i:i + seq_length]\n",
    "#     seq_out = raw_text[i + seq_length]\n",
    "#     dataX.append([char_to_int[char] for char in seq_in])\n",
    "#     dataY.append(char_to_int[seq_out])\n",
    "# n_patterns = len(dataX)\n",
    "# print (\"Total Patterns: \", n_patterns)\n",
    "# # reshape X to be [samples, time steps, features]\n",
    "# X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
    "# # normalize\n",
    "# X = X / float(n_vocab)\n",
    "# # one hot encode the output variable\n",
    "# y = np_utils.to_categorical(dataY)\n",
    "# # define the LSTM model\n",
    "# model = Sequential()\n",
    "# model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(y.shape[1], activation='softmax'))\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "# # define the checkpoint\n",
    "# filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "# checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "# callbacks_list = [checkpoint]\n",
    "# # fit the model\n",
    "# model.fit(X, y, epochs=20, batch_size=128, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resumption of the session\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re, os, pygtrie, numbers\n",
    "dimension = 29\n",
    "def readFile():\n",
    "    list = []\n",
    "    for i in os.listdir(\"assignment1-data/\"):\n",
    "        if i.startswith(\"training\"):\n",
    "            input = open(\"assignment1-data/\"+ i, 'r')\n",
    "            list.append(input.readlines())\n",
    "    return(list)\n",
    "def process_line(string):\n",
    "    string = re.sub(r'[^A-Za-z0-9\\ \\.]', \"\", string)\n",
    "    string = re.sub('[0-9]', \"0\",string)\n",
    "    line.strip('\\n')\n",
    "    string = string.lower()\n",
    "    return(string)\n",
    "processed_lines = []\n",
    "list = readFile()\n",
    "for l in list:\n",
    "    for line in l:\n",
    "        processed_lines.append(process_line(line))\n",
    "#     print('-------------------')\n",
    "# print(processed_lines)\n",
    "# for processed_line in processed_lines:\n",
    "print(processed_lines[0])\n",
    "\n",
    "triGram = np.zeros((29,29,29))\n",
    "# print(processed_lines)\n",
    "for processed_line in processed_lines:\n",
    "    constructTriGram(processed_line.strip(' ')) # shift it from the for above\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constructTriGram(line):\n",
    "    length = len(line)\n",
    "    listOfGrams = []\n",
    "    for i in range(length):\n",
    "        c = []\n",
    "        if i is 0 or i is 1:\n",
    "            continue\n",
    "        else:\n",
    "            enterSequence(line[i-2:i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord('.')%97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enterSequence(sequence):\n",
    "    seq=[]\n",
    "#     print(sequence)\n",
    "    seq.append(ord(sequence[0])%97)\n",
    "    seq.append(ord(sequence[1])%97)\n",
    "    seq.append(ord(sequence[2])%97)\n",
    "    seq = getascii(seq)\n",
    "#     print(seq)\n",
    "    triGram[seq[0]][seq[1]][seq[2]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getascii(seq):\n",
    "    for i in range(len(seq)):\n",
    "        if seq[i] == 32:\n",
    "            seq[i] = 26\n",
    "        if seq[i] == 46:\n",
    "            seq[i] = 27\n",
    "        if seq[i] == 48:\n",
    "            seq[i] = 28\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBigram(freq_matrix):\n",
    "    bi_grams = np.zeros((dimension,dimension))\n",
    "    for i in range(dimension):\n",
    "        for j in range(dimension):\n",
    "            bi_grams[i][j] = sum(freq_matrix[i][j])\n",
    "    return(bi_grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getUnigram(bi_grams):\n",
    "    uni_grams = np.zeros((dimension))\n",
    "    for i in range(dimension):\n",
    "        uni_grams[i] = sum(bi_grams[i])\n",
    "    return(uni_grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ -7.48629103e-01  -3.41277466e-01  -5.05672952e-03 ...,   3.49052564e-01\n",
      "    -7.51739883e-01  -7.32882641e-01]\n",
      "  [  5.56511762e-03  -4.30186792e-03   1.48480420e-03 ...,  -3.41836012e-03\n",
      "    -4.31934897e-03  -4.31189365e-03]\n",
      "  [  3.57282235e-03  -2.35253077e-03   2.55703980e-01 ...,  -1.58452864e-04\n",
      "    -2.35632043e-03  -2.20325120e-03]\n",
      "  ..., \n",
      "  [  3.55872033e-02   3.20696765e-02   7.54121858e-02 ...,   4.96844572e-03\n",
      "    -1.59868120e-03  -1.28360259e-03]\n",
      "  [ -1.40407773e-01  -1.29042743e+00  -9.27130488e-01 ...,   6.35489727e+00\n",
      "     5.47760649e-01   5.82580447e+00]\n",
      "  [ -9.14342553e-02  -9.58029985e-02  -5.11432236e-02 ...,   5.47024754e-01\n",
      "    -6.91474360e-02   2.89848804e+00]]\n",
      "\n",
      " [[ -5.94150082e-03   1.31644646e-02   6.34519307e-02 ...,   2.77025844e-03\n",
      "    -5.96618955e-03  -5.81652890e-03]\n",
      "  [  9.79460701e-01  -7.57128754e-01  -7.38674460e-01 ...,  -6.01631380e-01\n",
      "    -7.60205419e-01  -7.58893283e-01]\n",
      "  [  1.14330315e+00  -7.52809848e-01  -1.74726353e-01 ...,   9.49295084e-01\n",
      "    -7.54022537e-01  -7.05040383e-01]\n",
      "  ..., \n",
      "  [  3.36299793e-01   5.08478450e-03   6.71039393e-01 ...,  -8.37248697e-02\n",
      "    -9.37226851e-02  -7.52512017e-02]\n",
      "  [ -1.40407773e-01  -1.29042743e+00  -9.27130488e-01 ...,   6.35489727e+00\n",
      "     5.47760649e-01   5.82580447e+00]\n",
      "  [ -7.31474042e-01  -7.66423988e-01  -4.09145789e-01 ...,   4.37619804e+00\n",
      "    -5.53179488e-01   1.51879043e+01]]\n",
      "\n",
      " [[ -2.13284645e-03   1.87670238e-03  -1.44066368e-05 ...,   9.54146030e-03\n",
      "    -2.14170907e-03  -2.08798473e-03]\n",
      "  [  9.79460701e-01  -7.57128754e-01  -7.38674460e-01 ...,  -6.01631380e-01\n",
      "    -7.60205419e-01  -7.58893283e-01]\n",
      "  [  8.54514313e-02  -7.03560606e-03  -1.63295657e-03 ...,  -4.73877723e-04\n",
      "    -7.04693960e-03  -6.58916246e-03]\n",
      "  ..., \n",
      "  [  2.10160617e-01   1.60683329e-02   8.95142925e-02 ...,  -5.27400754e-03\n",
      "    -5.90379119e-03  -4.74023318e-03]\n",
      "  [ -1.40407773e-01  -1.29042743e+00  -9.27130488e-01 ...,   6.35489727e+00\n",
      "     5.47760649e-01   5.82580447e+00]\n",
      "  [ -8.12748936e-02  -8.51582209e-02  -4.54606432e-02 ...,   4.86244226e-01\n",
      "    -6.14643876e-02   2.68754493e+00]]\n",
      "\n",
      " ..., \n",
      " [[ -2.65001452e-04   2.35960080e-02   4.84937852e-02 ...,   1.42070461e-01\n",
      "    -2.66102613e-04   1.15650172e-03]\n",
      "  [  5.78378392e-02  -8.26559775e-04  -8.06413166e-04 ...,   1.52660330e-03\n",
      "    -8.29918579e-04  -8.28486117e-04]\n",
      "  [  1.18257377e-01  -5.81320346e-04  -1.34923825e-04 ...,   7.33046397e-04\n",
      "    -5.82256785e-04   5.63317345e-03]\n",
      "  ..., \n",
      "  [  3.18782204e-01   3.37853142e-02   1.04092390e-01 ...,  -7.44221064e-03\n",
      "    -8.33090534e-03   8.21998932e-02]\n",
      "  [ -1.40407773e-01  -1.29042743e+00  -9.27130488e-01 ...,   6.35489727e+00\n",
      "     1.54776065e+00   5.82580447e+00]\n",
      "  [ -4.25275606e-03  -4.45595342e-03  -2.37875459e-03 ...,   2.28931384e-01\n",
      "     4.91094216e-02   8.32487816e-01]]\n",
      "\n",
      " [[ -7.48629103e-01  -3.41277466e-01  -5.05672952e-03 ...,   3.49052564e-01\n",
      "    -7.51739883e-01  -7.32882641e-01]\n",
      "  [  9.79460701e-01  -7.57128754e-01  -7.38674460e-01 ...,  -6.01631380e-01\n",
      "    -7.60205419e-01  -7.58893283e-01]\n",
      "  [  1.14330315e+00  -7.52809848e-01  -1.74726353e-01 ...,  -5.07049164e-02\n",
      "    -7.54022537e-01  -7.05040383e-01]\n",
      "  ..., \n",
      "  [  4.22599585e-01   1.01695690e-02   9.20787859e-02 ...,  -1.67449739e-01\n",
      "    -1.87445370e-01   3.49497597e-01]\n",
      "  [ -7.02038866e-02  -6.45213714e-01  -4.63565244e-01 ...,   3.17744863e+00\n",
      "     1.27388032e+00   2.91290224e+00]\n",
      "  [ -1.04496292e-01  -1.09489141e-01  -5.84493984e-02 ...,   1.33945686e+00\n",
      "     6.38315017e-02   2.31255776e+00]]\n",
      "\n",
      " [[ -7.48629103e-01  -3.41277466e-01  -5.05672952e-03 ...,   3.49052564e-01\n",
      "    -7.51739883e-01  -7.32882641e-01]\n",
      "  [  9.79460701e-01  -7.57128754e-01  -7.38674460e-01 ...,  -6.01631380e-01\n",
      "    -7.60205419e-01  -7.58893283e-01]\n",
      "  [  1.03936650e-01  -6.84372589e-02  -1.58842139e-02 ...,   8.62995531e-02\n",
      "     1.13270678e-01  -6.40945803e-02]\n",
      "  ..., \n",
      "  [  1.29314990e-01   6.27542392e-02   2.73019696e-02 ...,   8.95637565e-02\n",
      "    -4.68613425e-03   5.87374399e-02]\n",
      "  [ -2.00582533e-02  -1.84346775e-01  -1.32447213e-01 ...,   9.07842467e-01\n",
      "     7.82515212e-02   1.83225778e+00]\n",
      "  [ -1.44274959e-03  -1.51168440e-03   2.08892588e-02 ...,   2.45317945e-01\n",
      "     2.45499418e-02   7.34098431e-01]]]\n"
     ]
    }
   ],
   "source": [
    "D = 0.75\n",
    "charCounts = dimension\n",
    "bi_gram_count = getBigram(triGram)\n",
    "uni_gram_count = getUnigram(bi_gram_count)\n",
    "uni_gram = (uni_gram_count / sum(uni_gram_count))\n",
    "bi_gram = np.zeros((dimension,dimension))\n",
    "tri_gram = np.zeros((dimension,dimension,dimension))\n",
    "for i in range(dimension):\n",
    "    for j in range(dimension):\n",
    "#         if bi_gram_count[i][j] > 0:\n",
    "        bi_gram[i][j] = ( (bi_gram_count[i][j] - D) / uni_gram_count[i] ) + (((D * charCounts) / uni_gram_count[i]) * uni_gram[j])\n",
    "# print(bi_gram)\n",
    "for w1 in range(dimension):\n",
    "    for w2 in range(dimension):\n",
    "        for w3 in range(dimension):\n",
    "            if bi_gram_count[w1][w2] > 0:\n",
    "                tri_gram[w1][w2][w3] = ((triGram[w1][w2][w3] - D) / bi_gram_count[w1][w2]) + ((D * charCounts) / bi_gram_count[w1][w2]) * bi_gram[w2][w3]\n",
    "            else:\n",
    "                tri_gram[w1][w2][w3] = ((triGram[w1][w2][w3] - D) ) + ((D * charCounts)) * bi_gram[w2][w3]\n",
    "#             print(tri_gram[w1][w2][w3] - D)\n",
    "print(tri_gram)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maxi = 0\n",
    "# i=0\n",
    "# j=0\n",
    "# k=0\n",
    "# for w1 in range(38):\n",
    "#     for w2 in range(38):\n",
    "#         for w3 in range(38):\n",
    "#             if abs(tri_gram[w1][w2][w3]) > maxi:\n",
    "#                 maxi = abs(tri_gram[w1][w2][w3])\n",
    "#                 i = w1\n",
    "#                 j = w2\n",
    "#                 k = w3\n",
    "# print(maxi)\n",
    "# from numpy import unravel_index\n",
    "# unravel_index(triGram.argmax(), triGram.shape)\n",
    "# triGram[26][19][8]              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unravel_index(tri_gram[26][19].argmax(), tri_gram[26][19].shape)\n",
    "tri_gram[3][13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class sequence(object):\n",
    "#     def __init__(self, char=\"\", probability=0):\n",
    "#         self.char = char[0]\n",
    "#         self.bigram = bigram(char[1])\n",
    "#         self.trigram = trigram(char[2], probability)\n",
    "        \n",
    "#     def printTrigram(self):\n",
    "#         print(self.char + self.bigram.printChar()+ self.trigram.printChar())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# class bigram(self, char = '', probablility):\n",
    "#     def __init__(self, char='', probability =0):\n",
    "#         self.char = [char, probability]\n",
    "#         self.gram ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s'"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asciiToChars(18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " n a pregivelys tood too tor an thican a somement ithess as truct of a printerstrion toressid ithavere as andevandstrucesideval truld trat issent oust onspere as itin toodst oust oulder se astak trin thavely trintioulat itionspeastruldirsend a propere ase astat ither the ce compeciam toods. trithint oulan on oft trur ands.m.0.0  as andendenders tran ons isse andstak it ithe trithic ands.m. ons astanspearlys intions in trin and is a stran thavis tood a fire as is iseduchas is trall pose cess trat \n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "theText = []\n",
    "def generateText():\n",
    "    temp = 0\n",
    "    first = 0\n",
    "    second = 0\n",
    "    theOne = 0\n",
    "    for i in range(500):\n",
    "        theOne = randint(0,2)\n",
    "        probableChar = sorted(range(len(tri_gram[first][second])), key=lambda i: tri_gram[first][second][i], reverse=True)[:3]\n",
    "        theText.append((probableChar[theOne]))\n",
    "        temp = (probableChar[theOne])\n",
    "        first = second\n",
    "        second = temp\n",
    "generateText()\n",
    "text = ' '\n",
    "for i in range(len(theText)):\n",
    "    text = text + asciiToChars(theText[i])\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asciiToChars(value):\n",
    "    char =''\n",
    "    if value < 26:\n",
    "        char = chr(int(value+97))\n",
    "    elif value == 26:\n",
    "        char = ' '\n",
    "    elif value == 27:\n",
    "        char = '.'\n",
    "    elif value == 28:\n",
    "        char = '0'\n",
    "#     elif (value > 26 & value < 37):\n",
    "#         char = chr(int(value+21))\n",
    "    return char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(28):\n",
    "    for j in range(28):\n",
    "        print(tri_gram[i][j].argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asciiToChars(27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "triGram = np.zeros((38,38,38))\n",
    "constructTriGram(\"resumption of the session\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTrainAndTestData(corpus, dev_part):\n",
    "    length = len(corpus)\n",
    "    folded_data = []\n",
    "    folds = 5\n",
    "    fold = int(length/5)\n",
    "    start = 0\n",
    "    print(fold)\n",
    "    for i in range(len(corpus)):\n",
    "        if (i%fold == 0):\n",
    "            folded_data.append(corpus[start:i])\n",
    "            start = i\n",
    "    print(folded_data)\n",
    "    dev = folded_data[dev_part]\n",
    "    train = folded_data.pop(dev_part)\n",
    "    print(dev)\n",
    "    print('---')\n",
    "    print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "['', 'Here w', 'e go, ', 'I am j', 'ust ch']\n",
      "Here w\n",
      "---\n",
      "Here w\n"
     ]
    }
   ],
   "source": [
    "getTrainAndTestData(\"Here we go, I am just checking\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "def getStratifiedSamplingOfData(corpus, dev_part):\n",
    "    sent_list = sent_tokenize(corpus)\n",
    "    train_data = []\n",
    "    test_data = []\n",
    "    for i in range(len(sent_list)):\n",
    "        if i%5 == 0:\n",
    "            test_data.append(sent_list[i])\n",
    "        else:\n",
    "            train_data.append(sent_list[i])\n",
    "    print(train_data)        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this is sent two.', 'is this sent three?', 'sent 4 is cool!', 'Now it’s your turn.']\n"
     ]
    }
   ],
   "source": [
    "whichPart = 0\n",
    "corpus = \"this’s a sent tokenize test. this is sent two. is this sent three? sent 4 is cool! Now it’s your turn.\"\n",
    "getStratifiedSamplingOfData(corpus, whichPart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[   0.    0.    0. ...,    0.    0.    0.]\n",
      "  [   0.    5.    1. ...,   10.    4.    0.]\n",
      "  [   0.    0.    0. ...,    0.    0.    0.]\n",
      "  ..., \n",
      "  [  10.   10.    0. ...,    5.    0.    2.]\n",
      "  [   0.    0.    0. ...,    2.    0.    0.]\n",
      "  [   0.    0.    0. ...,    0.    0.    8.]]\n",
      "\n",
      " [[   0.    0.    0. ...,    0.    0.    0.]\n",
      "  [   5.    0.    0. ...,    0.    0.    0.]\n",
      "  [   0.    0.    0. ...,    1.    0.    0.]\n",
      "  ..., \n",
      "  [   6.    3.    0. ...,    0.    0.    2.]\n",
      "  [   0.    0.    0. ...,    1.    0.    0.]\n",
      "  [   0.    0.    0. ...,    0.    0.    0.]]\n",
      "\n",
      " [[   0.    0.    0. ...,    0.    0.    0.]\n",
      "  [   0.    0.    0. ...,    0.    0.    0.]\n",
      "  [   2.    0.    0. ...,    0.    0.    0.]\n",
      "  ..., \n",
      "  [   1.    0.    0. ...,    0.    0.    0.]\n",
      "  [   0.    0.    0. ...,    0.    0.    0.]\n",
      "  [   0.    0.    0. ...,    0.    0.    8.]]\n",
      "\n",
      " ..., \n",
      " [[   0.  157.    6. ...,    2.    2.    4.]\n",
      "  [  19.    0.    0. ...,    2.    1.    0.]\n",
      "  [   2.    0.    0. ...,    4.    0.    8.]\n",
      "  ..., \n",
      "  [   9.    2.    7. ...,    0.    0.    8.]\n",
      "  [   0.    0.    0. ...,    0.    1.    0.]\n",
      "  [   0.    0.    0. ...,   19.    5.  126.]]\n",
      "\n",
      " [[   0.    0.    0. ...,    0.    0.    0.]\n",
      "  [   0.    0.    0. ...,    0.    0.    0.]\n",
      "  [   0.    0.    0. ...,    0.    0.    0.]\n",
      "  ..., \n",
      "  [   4.    2.    0. ...,    0.    0.    1.]\n",
      "  [   0.    0.    0. ...,    0.    1.    0.]\n",
      "  [   0.    0.    0. ...,    1.    0.    5.]]\n",
      "\n",
      " [[   0.    0.    0. ...,    0.    0.    0.]\n",
      "  [   0.    0.    0. ...,    0.    0.    0.]\n",
      "  [   0.    0.    0. ...,    0.    0.    0.]\n",
      "  ..., \n",
      "  [   8.   10.    3. ...,   25.    4.    6.]\n",
      "  [   0.    0.    0. ...,   12.    0.    6.]\n",
      "  [   0.    0.    8. ...,  122.   16.  344.]]]\n"
     ]
    }
   ],
   "source": [
    "print(triGram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
