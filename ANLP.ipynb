{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##resumption of the session#\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re, os, pygtrie, numbers\n",
    "dimension = 30\n",
    "def readFile(path):\n",
    "    list = []\n",
    "    input = open(path, 'r')\n",
    "    list.append(input.readlines())\n",
    "    return(list)\n",
    "def process_line(string):\n",
    "    string = re.sub(r'[^A-Za-z0-9\\ \\.]', \"\", string)\n",
    "    string = re.sub('[0-9]', \"0\",string)\n",
    "    string = string.lower()\n",
    "    string = \"##\" + string + \"#\"\n",
    "    return(string)\n",
    "processed_lines = []\n",
    "list = readFile(\"assignment1-data/training.en\")\n",
    "for l in list:\n",
    "    for line in l:\n",
    "        processed_lines.append(process_line(line))\n",
    "#     print('-------------------')\n",
    "# print(processed_lines)\n",
    "# for processed_line in processed_lines:\n",
    "print(processed_lines[0])\n",
    "\n",
    "triGram = np.zeros((30,30,30))\n",
    "# print(processed_lines)\n",
    "for processed_line in processed_lines:\n",
    "    constructTriGram(processed_line.strip(' ')) # shift it from the for above\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def constructTriGram(line):\n",
    "    length = len(line)\n",
    "    listOfGrams = []\n",
    "    for i in range(length):\n",
    "        c = []\n",
    "        if i is 0 or i is 1:\n",
    "            continue\n",
    "        else:\n",
    "            enterSequence(line[i-2:i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord('.')%97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def enterSequence(sequence):\n",
    "    seq=[]\n",
    "    seq.append(ord(sequence[0])%97)\n",
    "    seq.append(ord(sequence[1])%97)\n",
    "    seq.append(ord(sequence[2])%97)\n",
    "    seq = getascii(seq)\n",
    "    i = seq[0]\n",
    "    j = seq[1]\n",
    "    k = seq[2]\n",
    "    if ((i == 29 and j == 29 and k == 29)):\n",
    "        print('###')\n",
    "        print(asciiToChars(i)+asciiToChars(j)+asciiToChars(k))\n",
    "    elif (j == 29 and k == 29):\n",
    "        print('c##')\n",
    "        print(asciiToChars(i)+asciiToChars(j)+asciiToChars(k))\n",
    "    elif (i == 29 and k == 29):\n",
    "        print('#c#')\n",
    "        print(asciiToChars(i)+asciiToChars(j)+asciiToChars(k))\n",
    "    elif (i == 29 and k == 29 and j!=29):\n",
    "        print('#c#')\n",
    "        print(asciiToChars(i)+asciiToChars(j)+asciiToChars(k))\n",
    "    elif (i != 29 and j == 29 and k!=29):\n",
    "        print('c#c')\n",
    "        print(asciiToChars(i)+asciiToChars(j)+asciiToChars(k))\n",
    "    else:\n",
    "        triGram[i][j][k] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getascii(seq):\n",
    "    for i in range(len(seq)):\n",
    "        if seq[i] == 32:\n",
    "            seq[i] = 26\n",
    "        if seq[i] == 46:\n",
    "            seq[i] = 27\n",
    "        if seq[i] == 48:\n",
    "            seq[i] = 28\n",
    "        if seq[i] == 35:\n",
    "            seq[i] = 29\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getasciiForSingleChar(character):\n",
    "    char = ord(character)%97\n",
    "    if char == 32:\n",
    "        char = 26\n",
    "    if char == 46:\n",
    "        char = 27\n",
    "    if char == 48:\n",
    "        char = 28\n",
    "    if char == 35:\n",
    "        char = 29\n",
    "    return char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getBigram(freq_matrix):\n",
    "    bi_grams = np.zeros((dimension,dimension))\n",
    "    for i in range(dimension):\n",
    "        for j in range(dimension):\n",
    "            bi_grams[i][j] = sum(freq_matrix[i][j])\n",
    "    return(bi_grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getUnigram(bi_grams):\n",
    "    uni_grams = np.zeros((dimension))\n",
    "    for i in range(dimension):\n",
    "        uni_grams[i] = sum(bi_grams[i])\n",
    "    return(uni_grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateKNTriGram():\n",
    "    # D = [0.70, 0.20, 0.10]\n",
    "    D = 0.75\n",
    "    charCounts = dimension\n",
    "    bi_gram_count = getBigram(triGram)\n",
    "    uni_gram_count = getUnigram(bi_gram_count)\n",
    "    uni_gram = (uni_gram_count / sum(uni_gram_count))\n",
    "    bi_gram = np.zeros((dimension,dimension))\n",
    "    tri_gram = np.zeros((dimension,dimension,dimension))\n",
    "    for i in range(dimension):\n",
    "        for j in range(dimension):\n",
    "            if bi_gram_count[i][j] > 0:\n",
    "                bi_gram[i][j] = ( (bi_gram_count[i][j] - D) / uni_gram_count[i] ) + (((D * charCounts) / uni_gram_count[i]) * uni_gram[j])\n",
    "            else:\n",
    "                bi_gram[i][j] = (((D * charCounts) / uni_gram_count[i]) * uni_gram[j])\n",
    "                # print(bi_gram)\n",
    "    for w1 in range(dimension):\n",
    "        for w2 in range(dimension):\n",
    "            for w3 in range(dimension):\n",
    "                if triGram[w1][w2][w3] > 0:\n",
    "                    tri_gram[w1][w2][w3] = ((triGram[w1][w2][w3] - D) / bi_gram_count[w1][w2]) + ((D * charCounts) / bi_gram_count[w1][w2]) * bi_gram[w2][w3]\n",
    "                elif bi_gram_count[w1][w2] > 0:\n",
    "                    tri_gram[w1][w2][w3] = ((D * charCounts) / bi_gram_count[w1][w2]) * bi_gram[w2][w3]\n",
    "#                 else:\n",
    "#                     tri_gram[w1][w2][w3] = \n",
    "                    ##################### Work in pending #####################\n",
    "    print(tri_gram)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "     0.00000000e+00   0.00000000e+00]\n",
      "  [  1.01543529e-02   1.85899338e-05   1.48773777e-03 ...,   1.00508228e-04\n",
      "     8.26867193e-06   2.33248856e-05]\n",
      "  [  6.10435399e-03   4.02414690e-06   2.55761093e-01 ...,   1.43284707e-04\n",
      "     1.45019079e-04   5.04911782e-06]\n",
      "  ..., \n",
      "  [  8.18656943e-02   1.39446374e-02   3.54302267e-02 ...,   1.35553423e-01\n",
      "     3.82205151e-01   9.73378761e-01]\n",
      "  [  5.39805530e-03   9.19480674e-04   4.29964571e-02 ...,   8.82752081e-02\n",
      "     2.92281289e+00   1.15367713e-03]\n",
      "  [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "     0.00000000e+00   0.00000000e+00]]\n",
      "\n",
      " [[  2.59668916e-05   1.32692173e-02   6.36429198e-02 ...,   3.10147145e-04\n",
      "     1.40313463e-04   5.54966695e-06]\n",
      "  [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "     0.00000000e+00   0.00000000e+00]\n",
      "  [  1.95339328e+00   1.28772701e-03   5.93549606e-01 ...,   4.58511062e-02\n",
      "     4.64061053e-02   1.61571770e-03]\n",
      "  ..., \n",
      "  [  6.95858401e-01   1.18529418e-01   3.01156927e-01 ...,   1.15220410e+00\n",
      "     3.24874378e+00   7.73719470e-01]\n",
      "  [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "     0.00000000e+00   0.00000000e+00]\n",
      "  [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "     0.00000000e+00   0.00000000e+00]]\n",
      "\n",
      " [[  9.32144828e-06   1.91430593e-03   2.19090569e-03 ...,   1.11334873e-04\n",
      "     5.03689353e-05   1.99218813e-06]\n",
      "  [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "     0.00000000e+00   0.00000000e+00]\n",
      "  [  8.60130213e-02   1.20348319e-05   5.54719258e-03 ...,   4.28515011e-04\n",
      "     4.33701918e-04   1.51001654e-05]\n",
      "  ..., \n",
      "  [  1.54635200e-01   2.63398706e-02   6.69237616e-02 ...,   2.56045355e-01\n",
      "     7.21943062e-01   9.49715438e-01]\n",
      "  [  4.79827138e-03   8.17316155e-04   3.82190730e-02 ...,   7.84668516e-02\n",
      "     2.70916702e+00   1.02549078e-03]\n",
      "  [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "     0.00000000e+00   0.00000000e+00]]\n",
      "\n",
      " ..., \n",
      " [[  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "     0.00000000e+00   0.00000000e+00]\n",
      "  [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "     0.00000000e+00   0.00000000e+00]\n",
      "  [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "     0.00000000e+00   0.00000000e+00]\n",
      "  ..., \n",
      "  [  4.63905601e-01   7.90196119e-02   2.00771285e-01 ...,   1.18480273e+00\n",
      "     2.16582919e+00   1.82479647e-01]\n",
      "  [  6.16920606e-03   1.05083506e-03   4.91388081e-02 ...,   1.36600238e-01\n",
      "     2.34035759e+00   1.31848815e-03]\n",
      "  [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "     0.00000000e+00   0.00000000e+00]]\n",
      "\n",
      " [[  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "     0.00000000e+00   0.00000000e+00]\n",
      "  [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "     0.00000000e+00   0.00000000e+00]\n",
      "  [  1.77581207e-01   1.17066092e-04   5.39590551e-02 ...,   1.17804646e-01\n",
      "     4.21873684e-03   1.46883427e-04]\n",
      "  ..., \n",
      "  [  6.05094262e-02   1.03069059e-02   2.61875589e-02 ...,   1.00191661e-01\n",
      "     5.54238590e-01   6.75975606e-01]\n",
      "  [  8.48417336e-05   1.44515627e-05   2.08133038e-02 ...,   2.54542272e-02\n",
      "     7.31596273e-01   2.47392813e-03]\n",
      "  [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "     0.00000000e+00   0.00000000e+00]]\n",
      "\n",
      " [[  4.67404049e-05   6.02744832e-03   4.31286842e-02 ...,   5.58264862e-04\n",
      "     4.66811357e-02   9.98940050e-06]\n",
      "  [  9.40613739e-02   1.72201492e-04   6.23255128e-04 ...,   9.31023583e-04\n",
      "     7.65940137e-05   2.16062098e-04]\n",
      "  [  1.30226218e-01   8.58484672e-05   3.95699737e-02 ...,   3.05674042e-03\n",
      "     3.09374035e-03   1.07714513e-04]\n",
      "  ..., \n",
      "  [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "     0.00000000e+00   0.00000000e+00]\n",
      "  [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "     0.00000000e+00   0.00000000e+00]\n",
      "  [  7.00443714e-02   1.84579201e-02   1.44169380e-02 ...,   3.59901118e-08\n",
      "     1.15986315e-06   1.12448343e-02]]]\n"
     ]
    }
   ],
   "source": [
    "generateKNTriGram()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ccoures isenter a fuldinted is asent to bybbcatint oneregratiod a sen one tor to astake clan ouregrourouroultunise trinted.bat iss ase clan tring.#buropmad and a posent int traters it trioduchase astrioulans ansit trallempoleast oft it offor tratint is trulds.accus isse cludirs to bused astanspole coure tor as astruct in ould in ands thas ans tor se anspan thing to thesithis ingenteres ans the can ous a sends a sent oust is thativelin on trinte clustrultuatious isenden an as isedused.bcbalst tri\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "theText = []\n",
    "def generateText():\n",
    "    temp = 0\n",
    "    first = 0\n",
    "    second = 0\n",
    "    theOne = 0\n",
    "    for i in range(500):\n",
    "        theOne = randint(0,2)\n",
    "        probableChar = sorted(range(len(tri_gram_add_one[first][second])), key=lambda i: tri_gram_add_one[first][second][i], reverse=True)[:3]\n",
    "        theText.append((probableChar[theOne]))\n",
    "        temp = (probableChar[theOne])\n",
    "        first = second\n",
    "        second = temp\n",
    "generateText()\n",
    "text = ' '\n",
    "for i in range(len(theText)):\n",
    "    text = text + asciiToChars(theText[i])\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def asciiToChars(value):\n",
    "    char =''\n",
    "    if value < 26:\n",
    "        char = chr(int(value+97))\n",
    "    elif value == 26:\n",
    "        char = ' '\n",
    "    elif value == 27:\n",
    "        char = '.'\n",
    "    elif value == 28:\n",
    "        char = '0'\n",
    "    elif value == 29:\n",
    "        char = '#'\n",
    "    return char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTrainAndTestData(corpus, dev_part):\n",
    "    length = len(corpus)\n",
    "    folded_data = []\n",
    "    folds = 5\n",
    "    fold = int(length/5)\n",
    "    start = 0\n",
    "    print(fold)\n",
    "    for i in range(len(corpus)):\n",
    "        if (i%fold == 0):\n",
    "            folded_data.append(corpus[start:i])\n",
    "            start = i\n",
    "    print(folded_data)\n",
    "    dev = folded_data[dev_part]\n",
    "    train = folded_data.pop(dev_part)\n",
    "    print(dev)\n",
    "    print('---')\n",
    "    print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "['', 'Here w', 'e go, ', 'I am j', 'ust ch']\n",
      "Here w\n",
      "---\n",
      "Here w\n"
     ]
    }
   ],
   "source": [
    "getTrainAndTestData(\"Here we go, I am just checking\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "def getStratifiedSamplingOfData(corpus, dev_part):\n",
    "    sent_list = sent_tokenize(corpus)\n",
    "    train_data = []\n",
    "    test_data = []\n",
    "    for i in range(len(sent_list)):\n",
    "        if i%5 == 0:\n",
    "            test_data.append(sent_list[i])\n",
    "        else:\n",
    "            train_data.append(sent_list[i])\n",
    "    print(train_data)        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this is sent two.', 'is this sent three?', 'sent 4 is cool!', 'Now it’s your turn.']\n"
     ]
    }
   ],
   "source": [
    "whichPart = 0\n",
    "corpus = \"this’s a sent tokenize test. this is sent two. is this sent three? sent 4 is cool! Now it’s your turn.\"\n",
    "getStratifiedSamplingOfData(corpus, whichPart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.43346734e-04   1.87918407e-02   3.42502653e-02   3.30734188e-02\n",
      "    4.87425055e-04   1.07768133e-02   1.71923935e-02   2.23787232e-04\n",
      "    2.75960204e-02   1.74324081e-03   1.86698303e-02   1.22287842e-01\n",
      "    4.13140766e-02   1.82647944e-01   1.85961195e-04   1.77477963e-02\n",
      "    2.33333729e-06   1.10239081e-01   8.41098725e-02   1.64491146e-01\n",
      "    1.11134935e-02   2.43566011e-02   4.34093918e-03   1.63702650e-03\n",
      "    2.14725274e-02   2.74477679e-05   5.05311524e-02   3.22368968e-07\n",
      "    7.87004990e-04]\n",
      " [  7.95154346e-02   1.43346734e-04   5.20714485e-04   3.70342411e-04\n",
      "    4.19944457e-01   2.41132258e-04   1.83775556e-04   5.27465559e-04\n",
      "    2.99570591e-02   3.84914464e-02   5.58259895e-05   1.28721026e-01\n",
      "    4.89374826e-03   8.26944980e-04   4.82013226e-02   3.00830050e-04\n",
      "    1.36863716e-05   3.16661696e-02   3.60665761e-02   5.66477721e-03\n",
      "    9.03126901e-02   9.05742008e-04   1.79453544e-04   2.29606892e-05\n",
      "    8.19789328e-02   3.96184442e-06   6.82154574e-03   1.89088029e-06\n",
      "    6.22189657e-05]\n",
      " [  8.70484208e-02   5.65011144e-05   2.64493631e-02   1.45973042e-04\n",
      "    1.39775087e-01   9.50439600e-05   7.24364161e-05   1.09207657e-01\n",
      "    8.18746319e-02   7.02714865e-06   9.73975612e-03   3.19197507e-02\n",
      "    1.33906221e-04   3.25946127e-04   2.67575268e-01   1.18574261e-04\n",
      "    3.14877124e-04   2.58510874e-02   1.83659054e-03   1.21569281e-01\n",
      "    3.90635808e-02   4.75219800e-05   7.07328649e-05   9.05011569e-06\n",
      "    2.48849866e-02   1.56158859e-06   3.21514981e-02   7.45303645e-07\n",
      "    2.06710884e-03]\n",
      " [  5.41183009e-02   1.16267445e-04   1.40767678e-04   6.52554951e-03\n",
      "    1.85400334e-01   6.40379906e-04   3.04949445e-03   5.08078086e-04\n",
      "    9.01268267e-02   3.10815136e-04   8.23911926e-05   7.51856868e-03\n",
      "    1.52664350e-02   1.35339081e-03   3.95663763e-02   1.63601299e-03\n",
      "    5.29752094e-06   1.51744571e-02   4.45946971e-02   6.32587535e-03\n",
      "    2.83923663e-02   5.69947515e-03   3.73374676e-04   8.88728842e-06\n",
      "    6.93179213e-03   1.53349290e-06   4.87201532e-01   7.31894340e-07\n",
      "    2.40828090e-05]\n",
      " [  4.22638622e-02   3.70442252e-03   3.62997619e-02   5.19332078e-02\n",
      "    2.52585685e-02   1.15616519e-02   2.09605487e-02   1.68720261e-03\n",
      "    7.01866206e-03   3.28748297e-04   1.01761802e-03   2.94546508e-02\n",
      "    2.88858276e-02   1.12080624e-01   2.41258755e-03   1.41834156e-02\n",
      "    5.31089865e-03   1.00860273e-01   9.12691822e-02   2.24226660e-02\n",
      "    1.30031018e-02   1.96463591e-02   5.82559106e-03   1.34084799e-02\n",
      "    5.38804565e-03   2.02809371e-04   3.33511454e-01   1.40322016e-04\n",
      "    6.16919491e-06]\n",
      " [  4.35356878e-02   8.52158331e-05   2.16197707e-04   2.20158745e-04\n",
      "    7.41417383e-02   4.80335633e-02   1.09249696e-04   4.06917539e-04\n",
      "    1.01079775e-01   1.05984516e-05   3.31870707e-05   1.19207890e-02\n",
      "    1.04213862e-03   4.91596866e-04   1.88101757e-01   1.78835489e-04\n",
      "    8.13618507e-06   3.86155870e-02   5.29495590e-04   1.79306667e-02\n",
      "    6.48908897e-02   7.16733672e-05   9.46859612e-04   1.36495210e-05\n",
      "    3.55132973e-03   2.35521147e-06   4.07714675e-01   1.12407820e-06\n",
      "    3.69875255e-05]\n",
      " [  5.07538323e-02   1.11811857e-04   2.83673425e-04   4.82096282e-03\n",
      "    1.30108562e-01   1.29048631e-03   6.14530656e-03   6.17784053e-02\n",
      "    1.44875864e-01   1.39062486e-05   4.35448189e-05   3.39239245e-03\n",
      "    2.64991293e-04   1.20365000e-02   5.62158283e-02   2.34650387e-04\n",
      "    1.06755040e-05   1.44739119e-01   7.55413483e-03   5.39849354e-03\n",
      "    5.57461062e-02   9.40427620e-05   1.39975523e-04   1.79095626e-05\n",
      "    8.08939785e-03   3.09027747e-06   3.10563401e-01   1.47490515e-06\n",
      "    4.85314030e-05]\n",
      " [  1.80878896e-01   3.89566407e-05   1.41512028e-04   6.55443004e-04\n",
      "    4.85071966e-01   6.55313340e-05   4.99437837e-05   1.86023416e-04\n",
      "    1.38390515e-01   4.75217913e-05   1.51715560e-05   2.54760550e-03\n",
      "    9.88536570e-04   2.65730563e-03   5.83367200e-02   8.17551109e-05\n",
      "    3.71947826e-06   7.58151963e-03   1.77842082e-03   1.19525991e-02\n",
      "    3.88832412e-03   3.27656670e-05   2.62152619e-04   6.23991418e-06\n",
      "    5.54975436e-03   1.07669107e-06   1.00180932e-01   5.13875285e-07\n",
      "    1.69089439e-05]\n",
      " [  3.05845254e-02   8.79767406e-03   7.10777545e-02   3.43879472e-02\n",
      "    3.22712116e-02   1.53757465e-02   1.12899046e-02   1.08354894e-04\n",
      "    2.67638273e-04   2.76804866e-05   1.09713508e-02   2.97229664e-02\n",
      "    2.84171072e-02   2.27857860e-01   1.32120563e-01   6.33677254e-03\n",
      "    2.16652119e-06   2.28112302e-02   1.53367604e-01   1.11068741e-01\n",
      "    1.27053820e-03   3.20614439e-02   2.84070838e-05   1.51999139e-03\n",
      "    2.58984803e-05   2.51131622e-03   3.57820325e-02   2.24024091e-04\n",
      "    9.84911936e-06]\n",
      " [  4.84271303e-02   1.15256566e-03   2.92412859e-03   2.97770262e-03\n",
      "    4.47230178e-01   1.93880078e-03   1.47762972e-03   4.24103621e-03\n",
      "    8.54362680e-03   1.43346734e-04   4.48863512e-04   3.40339898e-03\n",
      "    2.73155166e-03   6.64897176e-03   2.25941948e-01   2.41879515e-03\n",
      "    1.10043958e-04   5.87142432e-03   5.89893531e-03   8.93093593e-03\n",
      "    2.81706074e-01   2.23202665e-03   1.44287900e-03   1.84613218e-04\n",
      "    1.31545968e-03   3.18548299e-05   1.82318223e-02   1.52034415e-05\n",
      "    5.00265623e-04]\n",
      " [  1.70783416e-02   3.68077421e-04   9.33834613e-04   9.50943739e-04\n",
      "    4.79921895e-01   6.19165411e-04   8.75114008e-04   1.75762124e-03\n",
      "    1.25309094e-01   4.57784732e-05   1.43346734e-04   7.94173064e-03\n",
      "    8.72334240e-04   3.80104781e-02   2.53814607e-02   7.72453935e-04\n",
      "    3.51430704e-05   1.87506777e-03   4.58354664e-02   2.85213760e-03\n",
      "    1.25452044e-03   7.12808512e-04   8.64016196e-04   5.89571246e-05\n",
      "    4.20098413e-04   1.01729940e-05   2.62677259e-01   4.85529261e-06\n",
      "    5.62988054e-04]\n",
      " [  8.75534082e-02   1.01724740e-04   6.01782059e-04   5.65495820e-02\n",
      "    1.40725713e-01   9.06910924e-03   3.28136712e-04   1.78626924e-04\n",
      "    1.43946317e-01   6.03757783e-06   2.84806419e-04   1.09534966e-01\n",
      "    1.68229574e-04   7.58667604e-04   6.46110414e-02   2.28226365e-03\n",
      "    4.63490824e-06   4.55489088e-03   3.09334161e-02   1.65961126e-02\n",
      "    1.84594347e-02   7.32651378e-03   3.30476283e-03   7.77566842e-06\n",
      "    1.01150917e-01   1.34168396e-06   2.02054861e-01   6.40349164e-07\n",
      "    2.10705368e-05]\n",
      " [  9.47756618e-02   3.24617567e-02   4.84754164e-04   1.56264277e-04\n",
      "    2.76053956e-01   4.33045999e-04   7.75432507e-05   2.22561667e-04\n",
      "    1.22897333e-01   7.52256915e-06   2.35555196e-05   5.09905380e-04\n",
      "    1.06491081e-01   1.21030915e-03   7.49367892e-02   9.21624494e-02\n",
      "    5.77490157e-06   4.78167352e-02   1.86636600e-02   4.68678854e-04\n",
      "    3.65167778e-02   5.08723237e-05   7.57195975e-05   9.68815724e-06\n",
      "    2.08084975e-02   1.67168203e-06   7.39093297e-02   7.97848243e-07\n",
      "    1.15267760e-03]\n",
      " [  3.82827278e-02   5.20696865e-05   4.61486256e-02   1.37395425e-01\n",
      "    6.98553544e-02   7.14654645e-03   8.31383461e-02   7.71964849e-04\n",
      "    3.54629397e-02   6.83621805e-04   7.65884963e-03   8.70251230e-03\n",
      "    1.71938668e-03   8.99025440e-03   4.53763617e-02   7.93686236e-05\n",
      "    2.95937177e-05   1.26583408e-04   6.40699030e-02   1.50372204e-01\n",
      "    8.35995238e-03   5.38348664e-03   5.83286195e-05   3.12013738e-05\n",
      "    5.71760246e-03   2.79080201e-05   2.74592759e-01   3.27774545e-07\n",
      "    1.07853434e-05]\n",
      " [  4.20333383e-03   1.21965485e-02   1.66662466e-02   1.88852059e-02\n",
      "    4.58549423e-03   9.94825345e-02   1.08527069e-02   4.34809307e-03\n",
      "    9.32416954e-03   1.56975725e-03   2.05775072e-03   2.38113667e-02\n",
      "    6.66143536e-02   2.12590790e-01   1.50179851e-02   4.52004746e-02\n",
      "    2.10112860e-06   1.28294363e-01   2.48233355e-02   3.63566370e-02\n",
      "    9.34211960e-02   1.28680753e-02   2.40632295e-02   5.09793001e-04\n",
      "    7.18519393e-03   6.08221438e-07   1.25251678e-01   2.43982914e-05\n",
      "    9.55184122e-06]\n",
      " [  9.71531194e-02   6.83052981e-05   1.73294660e-04   1.76469655e-04\n",
      "    1.74963058e-01   1.14900495e-04   1.62397691e-04   8.10826853e-03\n",
      "    1.66691524e-02   8.49525693e-06   1.01429205e-04   9.45596746e-02\n",
      "    1.99912742e-02   4.68870520e-04   2.22010328e-01   5.49921944e-02\n",
      "    6.52161138e-06   2.27899594e-01   6.41065226e-03   2.51476580e-02\n",
      "    1.69942540e-02   5.74502476e-05   8.55103387e-05   1.09408612e-05\n",
      "    4.52098478e-04   1.88783487e-06   3.43788988e-02   1.27297524e-03\n",
      "    2.96475886e-05]\n",
      " [  8.80639346e-03   1.50136843e-03   3.80906224e-03   3.87884946e-03\n",
      "    1.51419419e-02   2.52554312e-03   1.92480714e-03   5.52450770e-03\n",
      "    9.48446123e-03   1.86727983e-04   5.84703785e-04   4.43337499e-03\n",
      "    3.55820545e-03   8.66116058e-03   9.77964234e-03   3.15079894e-03\n",
      "    1.43346734e-04   7.64830273e-03   7.68413942e-03   1.16337192e-02\n",
      "    9.98538175e-01   1.26277156e-03   1.87953975e-03   2.40483008e-04\n",
      "    1.71355932e-03   4.14951073e-05   2.37493474e-02   1.98044830e-05\n",
      "    6.51661799e-04]\n",
      " [  9.09480360e-02   1.29201085e-03   6.88396763e-03   2.26682596e-02\n",
      "    2.79969368e-01   6.94683422e-04   1.03011801e-02   3.80977210e-04\n",
      "    6.87659233e-02   3.49971065e-06   9.41293156e-03   1.82396884e-02\n",
      "    1.53872808e-02   1.40032671e-02   1.10201789e-01   2.92588427e-03\n",
      "    2.68664656e-06   9.29871048e-03   4.14818729e-02   7.37383878e-02\n",
      "    2.31538598e-02   5.60319868e-03   2.53214427e-03   4.50720311e-06\n",
      "    2.13946314e-02   7.77713478e-07   1.71252762e-01   3.71181433e-07\n",
      "    1.22136367e-05]\n",
      " [  3.11227997e-02   4.26878743e-04   9.30645281e-03   1.57579592e-03\n",
      "    1.05492339e-01   1.67327965e-03   6.65894311e-05   3.04479290e-02\n",
      "    1.07105012e-01   3.48338898e-06   4.82804062e-03   6.12713218e-03\n",
      "    4.76078145e-03   1.92255327e-04   4.36593650e-02   3.07718362e-02\n",
      "    2.67411679e-06   9.09737606e-04   6.80434449e-02   1.12667934e-01\n",
      "    3.70370401e-02   2.35568578e-05   1.04758101e-03   4.48618278e-06\n",
      "    1.53540268e-03   7.74086440e-07   4.01799202e-01   3.69450346e-07\n",
      "    1.21566757e-05]\n",
      " [  4.47947934e-02   1.84993516e-05   1.28315317e-03   6.80597534e-05\n",
      "    9.39973715e-02   5.13847726e-05   4.39827079e-05   3.10075367e-01\n",
      "    1.14193550e-01   2.30079875e-06   7.20452134e-06   7.93805715e-03\n",
      "    1.03687153e-03   1.09974841e-03   9.23100280e-02   1.40152516e-04\n",
      "    1.76626975e-06   3.80522489e-02   2.38665685e-02   1.32959083e-02\n",
      "    2.21934016e-02   1.55594421e-05   5.71787371e-03   2.96314991e-06\n",
      "    1.81996158e-02   2.63967839e-04   2.11807709e-01   2.44024110e-07\n",
      "    8.02955524e-06]\n",
      " [  3.46519750e-02   1.77833265e-02   6.13332367e-02   1.19064598e-02\n",
      "    4.06169406e-02   3.43125545e-03   1.61712577e-02   2.28062241e-04\n",
      "    3.87538398e-02   7.70848816e-06   3.63627098e-04   1.26540976e-01\n",
      "    2.71023485e-02   1.25085958e-01   1.28639479e-03   3.98503317e-02\n",
      "    5.91762727e-06   2.07336378e-01   1.30749046e-01   8.14824349e-02\n",
      "    2.11244616e-04   5.21296245e-05   7.75909944e-05   7.78254800e-05\n",
      "    7.07390050e-05   1.71299737e-06   3.66268063e-02   8.17566926e-07\n",
      "    2.69018450e-05]\n",
      " [  6.54134218e-02   1.70431666e-04   4.32395414e-04   4.40317489e-04\n",
      "    7.24086315e-01   2.86693469e-04   2.18499391e-04   6.27128581e-04\n",
      "    1.43160297e-01   2.11969032e-05   6.63741414e-05   5.03265869e-04\n",
      "    4.03918767e-04   9.83193733e-04   6.77643806e-02   3.57670978e-04\n",
      "    1.62723701e-05   8.68216591e-04   8.72284684e-04   1.32063130e-03\n",
      "    3.94176756e-04   1.43346734e-04   2.13360748e-04   2.72990420e-05\n",
      "    1.12805154e-03   4.71042294e-06   2.88267424e-03   2.24815640e-06\n",
      "    7.39750511e-05]\n",
      " [  1.02151817e-01   1.14504767e-04   2.90505499e-04   2.95827957e-04\n",
      "    2.42624975e-01   1.92615431e-04   1.46799139e-04   2.16301919e-01\n",
      "    1.70944123e-01   1.42411708e-05   4.45935651e-05   2.97233969e-03\n",
      "    2.71373421e-04   2.23615135e-02   1.29822632e-01   3.65740813e-04\n",
      "    1.09326160e-05   4.72280081e-03   6.73255855e-03   6.53202474e-03\n",
      "    2.39729186e-03   9.63077156e-05   1.43346734e-04   1.83409018e-05\n",
      "    2.56126952e-04   3.16470462e-06   9.57651284e-02   1.51042721e-06\n",
      "    4.97002476e-05]\n",
      " [  1.47406164e-01   8.94933337e-04   9.73685391e-02   2.31209850e-03\n",
      "    5.70650007e-02   1.50542178e-03   1.14733602e-03   3.29303988e-03\n",
      "    1.24280934e-01   1.11304523e-04   3.48529315e-04   2.64263921e-03\n",
      "    2.12096952e-03   5.16273101e-03   6.80982602e-03   2.38152633e-01\n",
      "    8.54458965e-05   4.55898830e-03   4.58034977e-03   2.94189511e-01\n",
      "    2.06981441e-03   1.73310305e-03   1.12035310e-03   1.12373889e-03\n",
      "    1.02141575e-03   2.47343385e-05   5.43525522e-02   1.18050252e-05\n",
      "    3.88441543e-04]\n",
      " [  7.36693344e-04   1.25596038e-04   4.56234155e-04   1.01242989e-03\n",
      "    4.37818245e-02   3.48862165e-04   1.61018539e-04   4.62149240e-04\n",
      "    9.73672983e-03   1.56206128e-05   4.89130299e-05   3.70871215e-04\n",
      "    3.45574283e-02   4.16427981e-03   9.01136520e-02   5.35438714e-03\n",
      "    1.19915815e-05   6.39813988e-04   3.65536539e-02   5.51366280e-03\n",
      "    2.90480284e-04   1.05636366e-04   2.94821157e-04   2.01174558e-05\n",
      "    1.43346734e-04   3.47124728e-06   7.71524436e-01   1.65673166e-06\n",
      "    5.45143607e-05]\n",
      " [  3.04220865e-02   5.18654548e-03   1.31585786e-02   1.33996618e-02\n",
      "    6.26172163e-01   8.72460351e-03   6.64933374e-03   1.90846629e-02\n",
      "    1.06628139e-01   6.45060304e-04   2.01988580e-03   2.09971136e-02\n",
      "    1.22919825e-02   2.99203729e-02   1.98556946e-01   1.08845782e-02\n",
      "    4.95197810e-04   2.64214094e-02   2.65452089e-02   4.01892117e-02\n",
      "    1.19955154e-02   4.36230176e-03   6.49295549e-03   8.30759483e-04\n",
      "    5.91956855e-03   1.43346734e-04   1.78634109e-01   6.84154868e-05\n",
      "    2.25119531e-03]\n",
      " [  1.12202223e-01   3.63530242e-02   5.14167882e-02   2.71548102e-02\n",
      "    3.23055861e-02   3.52076354e-02   1.56273109e-02   2.60925912e-02\n",
      "    8.26625755e-02   3.26721926e-03   2.67398145e-03   1.75484999e-02\n",
      "    3.77155560e-02   1.89241352e-02   7.35709211e-02   5.39542120e-02\n",
      "    2.43306154e-03   3.97654188e-02   5.69200647e-02   1.80717878e-01\n",
      "    1.27378709e-02   6.92697221e-03   5.51378188e-02   1.13788436e-05\n",
      "    7.88271695e-03   2.88143083e-04   3.68740423e-03   1.00468682e-05\n",
      "    6.80415568e-03]\n",
      " [  6.37415145e-02   1.08670477e-02   2.75703552e-02   2.80754818e-02\n",
      "    2.16741675e-01   1.82801216e-02   1.39319374e-02   3.99869128e-02\n",
      "    6.86494337e-02   1.35155492e-03   4.23214168e-03   3.20891904e-02\n",
      "    2.28135582e-01   6.26903051e-02   7.07859826e-02   2.28057828e-02\n",
      "    1.03755732e-03   5.53591436e-02   5.56185329e-02   8.42059674e-02\n",
      "    2.51334608e-02   9.14006082e-03   1.36042877e-02   1.74063892e-03\n",
      "    1.24029055e-02   3.00345539e-04   3.26661943e-01   5.96671563e-02\n",
      "    3.02335838e-01]\n",
      " [  1.93715167e-03   3.30257599e-04   1.56714580e-02   8.53234614e-04\n",
      "    9.48129547e-03   5.55546389e-04   4.23401859e-04   1.21523179e-03\n",
      "    2.08630696e-03   4.10747517e-05   1.28617909e-04   9.75214180e-04\n",
      "    7.82702212e-04   1.90520464e-03   2.15123826e-03   6.93084572e-04\n",
      "    3.15321326e-05   1.68240523e-03   2.05208277e-03   2.55908150e-03\n",
      "    7.63824422e-04   2.77773194e-04   4.13444344e-04   5.28993014e-05\n",
      "    3.76933453e-04   9.12772259e-06   2.35687266e-01   9.04921893e-03\n",
      "    7.32777211e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(bi_gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from decimal import Decimal\n",
    "def createArpa(): \n",
    "    file = open(\"trigram_add_one.en\",\"w\")\n",
    "    for i in range(30):\n",
    "        for j in range(30):\n",
    "            for k in range(30):\n",
    "                if ((i == 29 and j == 29 and k == 29)):\n",
    "#                     print('###')\n",
    "                    print(asciiToChars(i)+asciiToChars(j)+asciiToChars(k))\n",
    "                    continue\n",
    "                elif (j == 29 and k == 29):\n",
    "#                     print('c##')\n",
    "                    print(asciiToChars(i)+asciiToChars(j)+asciiToChars(k))\n",
    "                    continue\n",
    "                elif (i != 29 and j == 29 and k!=29):\n",
    "#                     print('c#c')\n",
    "                    print(asciiToChars(i)+asciiToChars(j)+asciiToChars(k))\n",
    "                    continue\n",
    "                else:\n",
    "                    s = \"\"\n",
    "                    listSeq = []\n",
    "                    listSeq.append(asciiToChars(i))\n",
    "                    listSeq.append(asciiToChars(j))\n",
    "                    listSeq.append(asciiToChars(k))\n",
    "                    listSeq.append(\"\\t\")\n",
    "                    listSeq.append(str(tri_gram_one[i][j][k]))\n",
    "#                     print(tri_gram_one[i][j][k])\n",
    "                    listSeq.append(\"\\n\")\n",
    "                    file.write(s.join(listSeq)) \n",
    "    file.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a#a\n",
      "a#b\n",
      "a#c\n",
      "a#d\n",
      "a#e\n",
      "a#f\n",
      "a#g\n",
      "a#h\n",
      "a#i\n",
      "a#j\n",
      "a#k\n",
      "a#l\n",
      "a#m\n",
      "a#n\n",
      "a#o\n",
      "a#p\n",
      "a#q\n",
      "a#r\n",
      "a#s\n",
      "a#t\n",
      "a#u\n",
      "a#v\n",
      "a#w\n",
      "a#x\n",
      "a#y\n",
      "a#z\n",
      "a# \n",
      "a#.\n",
      "a#0\n",
      "a##\n",
      "b#a\n",
      "b#b\n",
      "b#c\n",
      "b#d\n",
      "b#e\n",
      "b#f\n",
      "b#g\n",
      "b#h\n",
      "b#i\n",
      "b#j\n",
      "b#k\n",
      "b#l\n",
      "b#m\n",
      "b#n\n",
      "b#o\n",
      "b#p\n",
      "b#q\n",
      "b#r\n",
      "b#s\n",
      "b#t\n",
      "b#u\n",
      "b#v\n",
      "b#w\n",
      "b#x\n",
      "b#y\n",
      "b#z\n",
      "b# \n",
      "b#.\n",
      "b#0\n",
      "b##\n",
      "c#a\n",
      "c#b\n",
      "c#c\n",
      "c#d\n",
      "c#e\n",
      "c#f\n",
      "c#g\n",
      "c#h\n",
      "c#i\n",
      "c#j\n",
      "c#k\n",
      "c#l\n",
      "c#m\n",
      "c#n\n",
      "c#o\n",
      "c#p\n",
      "c#q\n",
      "c#r\n",
      "c#s\n",
      "c#t\n",
      "c#u\n",
      "c#v\n",
      "c#w\n",
      "c#x\n",
      "c#y\n",
      "c#z\n",
      "c# \n",
      "c#.\n",
      "c#0\n",
      "c##\n",
      "d#a\n",
      "d#b\n",
      "d#c\n",
      "d#d\n",
      "d#e\n",
      "d#f\n",
      "d#g\n",
      "d#h\n",
      "d#i\n",
      "d#j\n",
      "d#k\n",
      "d#l\n",
      "d#m\n",
      "d#n\n",
      "d#o\n",
      "d#p\n",
      "d#q\n",
      "d#r\n",
      "d#s\n",
      "d#t\n",
      "d#u\n",
      "d#v\n",
      "d#w\n",
      "d#x\n",
      "d#y\n",
      "d#z\n",
      "d# \n",
      "d#.\n",
      "d#0\n",
      "d##\n",
      "e#a\n",
      "e#b\n",
      "e#c\n",
      "e#d\n",
      "e#e\n",
      "e#f\n",
      "e#g\n",
      "e#h\n",
      "e#i\n",
      "e#j\n",
      "e#k\n",
      "e#l\n",
      "e#m\n",
      "e#n\n",
      "e#o\n",
      "e#p\n",
      "e#q\n",
      "e#r\n",
      "e#s\n",
      "e#t\n",
      "e#u\n",
      "e#v\n",
      "e#w\n",
      "e#x\n",
      "e#y\n",
      "e#z\n",
      "e# \n",
      "e#.\n",
      "e#0\n",
      "e##\n",
      "f#a\n",
      "f#b\n",
      "f#c\n",
      "f#d\n",
      "f#e\n",
      "f#f\n",
      "f#g\n",
      "f#h\n",
      "f#i\n",
      "f#j\n",
      "f#k\n",
      "f#l\n",
      "f#m\n",
      "f#n\n",
      "f#o\n",
      "f#p\n",
      "f#q\n",
      "f#r\n",
      "f#s\n",
      "f#t\n",
      "f#u\n",
      "f#v\n",
      "f#w\n",
      "f#x\n",
      "f#y\n",
      "f#z\n",
      "f# \n",
      "f#.\n",
      "f#0\n",
      "f##\n",
      "g#a\n",
      "g#b\n",
      "g#c\n",
      "g#d\n",
      "g#e\n",
      "g#f\n",
      "g#g\n",
      "g#h\n",
      "g#i\n",
      "g#j\n",
      "g#k\n",
      "g#l\n",
      "g#m\n",
      "g#n\n",
      "g#o\n",
      "g#p\n",
      "g#q\n",
      "g#r\n",
      "g#s\n",
      "g#t\n",
      "g#u\n",
      "g#v\n",
      "g#w\n",
      "g#x\n",
      "g#y\n",
      "g#z\n",
      "g# \n",
      "g#.\n",
      "g#0\n",
      "g##\n",
      "h#a\n",
      "h#b\n",
      "h#c\n",
      "h#d\n",
      "h#e\n",
      "h#f\n",
      "h#g\n",
      "h#h\n",
      "h#i\n",
      "h#j\n",
      "h#k\n",
      "h#l\n",
      "h#m\n",
      "h#n\n",
      "h#o\n",
      "h#p\n",
      "h#q\n",
      "h#r\n",
      "h#s\n",
      "h#t\n",
      "h#u\n",
      "h#v\n",
      "h#w\n",
      "h#x\n",
      "h#y\n",
      "h#z\n",
      "h# \n",
      "h#.\n",
      "h#0\n",
      "h##\n",
      "i#a\n",
      "i#b\n",
      "i#c\n",
      "i#d\n",
      "i#e\n",
      "i#f\n",
      "i#g\n",
      "i#h\n",
      "i#i\n",
      "i#j\n",
      "i#k\n",
      "i#l\n",
      "i#m\n",
      "i#n\n",
      "i#o\n",
      "i#p\n",
      "i#q\n",
      "i#r\n",
      "i#s\n",
      "i#t\n",
      "i#u\n",
      "i#v\n",
      "i#w\n",
      "i#x\n",
      "i#y\n",
      "i#z\n",
      "i# \n",
      "i#.\n",
      "i#0\n",
      "i##\n",
      "j#a\n",
      "j#b\n",
      "j#c\n",
      "j#d\n",
      "j#e\n",
      "j#f\n",
      "j#g\n",
      "j#h\n",
      "j#i\n",
      "j#j\n",
      "j#k\n",
      "j#l\n",
      "j#m\n",
      "j#n\n",
      "j#o\n",
      "j#p\n",
      "j#q\n",
      "j#r\n",
      "j#s\n",
      "j#t\n",
      "j#u\n",
      "j#v\n",
      "j#w\n",
      "j#x\n",
      "j#y\n",
      "j#z\n",
      "j# \n",
      "j#.\n",
      "j#0\n",
      "j##\n",
      "k#a\n",
      "k#b\n",
      "k#c\n",
      "k#d\n",
      "k#e\n",
      "k#f\n",
      "k#g\n",
      "k#h\n",
      "k#i\n",
      "k#j\n",
      "k#k\n",
      "k#l\n",
      "k#m\n",
      "k#n\n",
      "k#o\n",
      "k#p\n",
      "k#q\n",
      "k#r\n",
      "k#s\n",
      "k#t\n",
      "k#u\n",
      "k#v\n",
      "k#w\n",
      "k#x\n",
      "k#y\n",
      "k#z\n",
      "k# \n",
      "k#.\n",
      "k#0\n",
      "k##\n",
      "l#a\n",
      "l#b\n",
      "l#c\n",
      "l#d\n",
      "l#e\n",
      "l#f\n",
      "l#g\n",
      "l#h\n",
      "l#i\n",
      "l#j\n",
      "l#k\n",
      "l#l\n",
      "l#m\n",
      "l#n\n",
      "l#o\n",
      "l#p\n",
      "l#q\n",
      "l#r\n",
      "l#s\n",
      "l#t\n",
      "l#u\n",
      "l#v\n",
      "l#w\n",
      "l#x\n",
      "l#y\n",
      "l#z\n",
      "l# \n",
      "l#.\n",
      "l#0\n",
      "l##\n",
      "m#a\n",
      "m#b\n",
      "m#c\n",
      "m#d\n",
      "m#e\n",
      "m#f\n",
      "m#g\n",
      "m#h\n",
      "m#i\n",
      "m#j\n",
      "m#k\n",
      "m#l\n",
      "m#m\n",
      "m#n\n",
      "m#o\n",
      "m#p\n",
      "m#q\n",
      "m#r\n",
      "m#s\n",
      "m#t\n",
      "m#u\n",
      "m#v\n",
      "m#w\n",
      "m#x\n",
      "m#y\n",
      "m#z\n",
      "m# \n",
      "m#.\n",
      "m#0\n",
      "m##\n",
      "n#a\n",
      "n#b\n",
      "n#c\n",
      "n#d\n",
      "n#e\n",
      "n#f\n",
      "n#g\n",
      "n#h\n",
      "n#i\n",
      "n#j\n",
      "n#k\n",
      "n#l\n",
      "n#m\n",
      "n#n\n",
      "n#o\n",
      "n#p\n",
      "n#q\n",
      "n#r\n",
      "n#s\n",
      "n#t\n",
      "n#u\n",
      "n#v\n",
      "n#w\n",
      "n#x\n",
      "n#y\n",
      "n#z\n",
      "n# \n",
      "n#.\n",
      "n#0\n",
      "n##\n",
      "o#a\n",
      "o#b\n",
      "o#c\n",
      "o#d\n",
      "o#e\n",
      "o#f\n",
      "o#g\n",
      "o#h\n",
      "o#i\n",
      "o#j\n",
      "o#k\n",
      "o#l\n",
      "o#m\n",
      "o#n\n",
      "o#o\n",
      "o#p\n",
      "o#q\n",
      "o#r\n",
      "o#s\n",
      "o#t\n",
      "o#u\n",
      "o#v\n",
      "o#w\n",
      "o#x\n",
      "o#y\n",
      "o#z\n",
      "o# \n",
      "o#.\n",
      "o#0\n",
      "o##\n",
      "p#a\n",
      "p#b\n",
      "p#c\n",
      "p#d\n",
      "p#e\n",
      "p#f\n",
      "p#g\n",
      "p#h\n",
      "p#i\n",
      "p#j\n",
      "p#k\n",
      "p#l\n",
      "p#m\n",
      "p#n\n",
      "p#o\n",
      "p#p\n",
      "p#q\n",
      "p#r\n",
      "p#s\n",
      "p#t\n",
      "p#u\n",
      "p#v\n",
      "p#w\n",
      "p#x\n",
      "p#y\n",
      "p#z\n",
      "p# \n",
      "p#.\n",
      "p#0\n",
      "p##\n",
      "q#a\n",
      "q#b\n",
      "q#c\n",
      "q#d\n",
      "q#e\n",
      "q#f\n",
      "q#g\n",
      "q#h\n",
      "q#i\n",
      "q#j\n",
      "q#k\n",
      "q#l\n",
      "q#m\n",
      "q#n\n",
      "q#o\n",
      "q#p\n",
      "q#q\n",
      "q#r\n",
      "q#s\n",
      "q#t\n",
      "q#u\n",
      "q#v\n",
      "q#w\n",
      "q#x\n",
      "q#y\n",
      "q#z\n",
      "q# \n",
      "q#.\n",
      "q#0\n",
      "q##\n",
      "r#a\n",
      "r#b\n",
      "r#c\n",
      "r#d\n",
      "r#e\n",
      "r#f\n",
      "r#g\n",
      "r#h\n",
      "r#i\n",
      "r#j\n",
      "r#k\n",
      "r#l\n",
      "r#m\n",
      "r#n\n",
      "r#o\n",
      "r#p\n",
      "r#q\n",
      "r#r\n",
      "r#s\n",
      "r#t\n",
      "r#u\n",
      "r#v\n",
      "r#w\n",
      "r#x\n",
      "r#y\n",
      "r#z\n",
      "r# \n",
      "r#.\n",
      "r#0\n",
      "r##\n",
      "s#a\n",
      "s#b\n",
      "s#c\n",
      "s#d\n",
      "s#e\n",
      "s#f\n",
      "s#g\n",
      "s#h\n",
      "s#i\n",
      "s#j\n",
      "s#k\n",
      "s#l\n",
      "s#m\n",
      "s#n\n",
      "s#o\n",
      "s#p\n",
      "s#q\n",
      "s#r\n",
      "s#s\n",
      "s#t\n",
      "s#u\n",
      "s#v\n",
      "s#w\n",
      "s#x\n",
      "s#y\n",
      "s#z\n",
      "s# \n",
      "s#.\n",
      "s#0\n",
      "s##\n",
      "t#a\n",
      "t#b\n",
      "t#c\n",
      "t#d\n",
      "t#e\n",
      "t#f\n",
      "t#g\n",
      "t#h\n",
      "t#i\n",
      "t#j\n",
      "t#k\n",
      "t#l\n",
      "t#m\n",
      "t#n\n",
      "t#o\n",
      "t#p\n",
      "t#q\n",
      "t#r\n",
      "t#s\n",
      "t#t\n",
      "t#u\n",
      "t#v\n",
      "t#w\n",
      "t#x\n",
      "t#y\n",
      "t#z\n",
      "t# \n",
      "t#.\n",
      "t#0\n",
      "t##\n",
      "u#a\n",
      "u#b\n",
      "u#c\n",
      "u#d\n",
      "u#e\n",
      "u#f\n",
      "u#g\n",
      "u#h\n",
      "u#i\n",
      "u#j\n",
      "u#k\n",
      "u#l\n",
      "u#m\n",
      "u#n\n",
      "u#o\n",
      "u#p\n",
      "u#q\n",
      "u#r\n",
      "u#s\n",
      "u#t\n",
      "u#u\n",
      "u#v\n",
      "u#w\n",
      "u#x\n",
      "u#y\n",
      "u#z\n",
      "u# \n",
      "u#.\n",
      "u#0\n",
      "u##\n",
      "v#a\n",
      "v#b\n",
      "v#c\n",
      "v#d\n",
      "v#e\n",
      "v#f\n",
      "v#g\n",
      "v#h\n",
      "v#i\n",
      "v#j\n",
      "v#k\n",
      "v#l\n",
      "v#m\n",
      "v#n\n",
      "v#o\n",
      "v#p\n",
      "v#q\n",
      "v#r\n",
      "v#s\n",
      "v#t\n",
      "v#u\n",
      "v#v\n",
      "v#w\n",
      "v#x\n",
      "v#y\n",
      "v#z\n",
      "v# \n",
      "v#.\n",
      "v#0\n",
      "v##\n",
      "w#a\n",
      "w#b\n",
      "w#c\n",
      "w#d\n",
      "w#e\n",
      "w#f\n",
      "w#g\n",
      "w#h\n",
      "w#i\n",
      "w#j\n",
      "w#k\n",
      "w#l\n",
      "w#m\n",
      "w#n\n",
      "w#o\n",
      "w#p\n",
      "w#q\n",
      "w#r\n",
      "w#s\n",
      "w#t\n",
      "w#u\n",
      "w#v\n",
      "w#w\n",
      "w#x\n",
      "w#y\n",
      "w#z\n",
      "w# \n",
      "w#.\n",
      "w#0\n",
      "w##\n",
      "x#a\n",
      "x#b\n",
      "x#c\n",
      "x#d\n",
      "x#e\n",
      "x#f\n",
      "x#g\n",
      "x#h\n",
      "x#i\n",
      "x#j\n",
      "x#k\n",
      "x#l\n",
      "x#m\n",
      "x#n\n",
      "x#o\n",
      "x#p\n",
      "x#q\n",
      "x#r\n",
      "x#s\n",
      "x#t\n",
      "x#u\n",
      "x#v\n",
      "x#w\n",
      "x#x\n",
      "x#y\n",
      "x#z\n",
      "x# \n",
      "x#.\n",
      "x#0\n",
      "x##\n",
      "y#a\n",
      "y#b\n",
      "y#c\n",
      "y#d\n",
      "y#e\n",
      "y#f\n",
      "y#g\n",
      "y#h\n",
      "y#i\n",
      "y#j\n",
      "y#k\n",
      "y#l\n",
      "y#m\n",
      "y#n\n",
      "y#o\n",
      "y#p\n",
      "y#q\n",
      "y#r\n",
      "y#s\n",
      "y#t\n",
      "y#u\n",
      "y#v\n",
      "y#w\n",
      "y#x\n",
      "y#y\n",
      "y#z\n",
      "y# \n",
      "y#.\n",
      "y#0\n",
      "y##\n",
      "z#a\n",
      "z#b\n",
      "z#c\n",
      "z#d\n",
      "z#e\n",
      "z#f\n",
      "z#g\n",
      "z#h\n",
      "z#i\n",
      "z#j\n",
      "z#k\n",
      "z#l\n",
      "z#m\n",
      "z#n\n",
      "z#o\n",
      "z#p\n",
      "z#q\n",
      "z#r\n",
      "z#s\n",
      "z#t\n",
      "z#u\n",
      "z#v\n",
      "z#w\n",
      "z#x\n",
      "z#y\n",
      "z#z\n",
      "z# \n",
      "z#.\n",
      "z#0\n",
      "z##\n",
      " #a\n",
      " #b\n",
      " #c\n",
      " #d\n",
      " #e\n",
      " #f\n",
      " #g\n",
      " #h\n",
      " #i\n",
      " #j\n",
      " #k\n",
      " #l\n",
      " #m\n",
      " #n\n",
      " #o\n",
      " #p\n",
      " #q\n",
      " #r\n",
      " #s\n",
      " #t\n",
      " #u\n",
      " #v\n",
      " #w\n",
      " #x\n",
      " #y\n",
      " #z\n",
      " # \n",
      " #.\n",
      " #0\n",
      " ##\n",
      ".#a\n",
      ".#b\n",
      ".#c\n",
      ".#d\n",
      ".#e\n",
      ".#f\n",
      ".#g\n",
      ".#h\n",
      ".#i\n",
      ".#j\n",
      ".#k\n",
      ".#l\n",
      ".#m\n",
      ".#n\n",
      ".#o\n",
      ".#p\n",
      ".#q\n",
      ".#r\n",
      ".#s\n",
      ".#t\n",
      ".#u\n",
      ".#v\n",
      ".#w\n",
      ".#x\n",
      ".#y\n",
      ".#z\n",
      ".# \n",
      ".#.\n",
      ".#0\n",
      ".##\n",
      "0#a\n",
      "0#b\n",
      "0#c\n",
      "0#d\n",
      "0#e\n",
      "0#f\n",
      "0#g\n",
      "0#h\n",
      "0#i\n",
      "0#j\n",
      "0#k\n",
      "0#l\n",
      "0#m\n",
      "0#n\n",
      "0#o\n",
      "0#p\n",
      "0#q\n",
      "0#r\n",
      "0#s\n",
      "0#t\n",
      "0#u\n",
      "0#v\n",
      "0#w\n",
      "0#x\n",
      "0#y\n",
      "0#z\n",
      "0# \n",
      "0#.\n",
      "0#0\n",
      "0##\n",
      "###\n"
     ]
    }
   ],
   "source": [
    "createArpa()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateAddOneSmoothing(alpha):\n",
    "    tri_gram_add_one = np.zeros((dimension, dimension, dimension))\n",
    "    for w1 in range(dimension):\n",
    "        for w2 in range(dimension):\n",
    "            for w3 in range(dimension):\n",
    "                tri_gram_add_one[w1][w2][w3] = ((triGram[w1][w2][w3] + alpha) / (sum(triGram[w1][w2]) + (alpha*(dimension))))\n",
    "    return(tri_gram_add_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tri_gram_one = generateAddOneSmoothing(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "\n",
    "# method for generating text\n",
    "def generate_text(model, length, vocab_size, ix_to_char):\n",
    "    ix = [np.random.randint(vocab_size)]\n",
    "    y_char = [ix_to_char[ix[-1]]]\n",
    "    X = np.zeros((1, length, vocab_size))\n",
    "    for i in range(length):\n",
    "        X[0, i, :][ix[-1]] = 1\n",
    "        print(ix_to_char[ix[-1]], end=\"\")\n",
    "        ix = np.argmax(model.predict(X[:, :i+1, :])[0], 1)\n",
    "        y_char.append(ix_to_char[ix[-1]])\n",
    "    return ('').join(y_char)\n",
    "\n",
    "\n",
    "def load_data(data_dir, seq_length):\n",
    "    data = open(data_dir, 'r').read()\n",
    "    chars = list(set(data))\n",
    "    VOCAB_SIZE = len(chars)\n",
    "\n",
    "    print('Data length: {} characters'.format(len(data)))\n",
    "    print('Vocabulary size: {} characters'.format(VOCAB_SIZE))\n",
    "\n",
    "    ix_to_char = {ix:char for ix, char in enumerate(chars)}\n",
    "    char_to_ix = {char:ix for ix, char in enumerate(chars)}\n",
    "\n",
    "    X = np.zeros((int(len(data)/seq_length), seq_length, VOCAB_SIZE))\n",
    "    y = np.zeros((int(len(data)/seq_length), seq_length, VOCAB_SIZE))\n",
    "    for i in range(0, int(len(data)/seq_length)):\n",
    "        X_sequence = data[i*seq_length:(i+1)*seq_length]\n",
    "        X_sequence_ix = [char_to_ix[value] for value in X_sequence]\n",
    "        input_sequence = np.zeros((seq_length, VOCAB_SIZE))\n",
    "        for j in range(seq_length):\n",
    "            input_sequence[j][X_sequence_ix[j]] = 1.\n",
    "            X[i] = input_sequence\n",
    "\n",
    "        y_sequence = data[i*seq_length+1:(i+1)*seq_length+1]\n",
    "        y_sequence_ix = [char_to_ix[value] for value in y_sequence]\n",
    "        target_sequence = np.zeros((seq_length, VOCAB_SIZE))\n",
    "        for j in range(seq_length):\n",
    "            target_sequence[j][y_sequence_ix[j]] = 1.\n",
    "            y[i] = target_sequence\n",
    "    return X, y, VOCAB_SIZE, ix_to_char\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data length: 156902 characters\n",
      "Vocabulary size: 85 characters\n",
      "]óVbb'DFF'qqSwwwo!!!!D!!(qqqqwwNNN(((SDD!((55D!!D(((''QJJqqqzzJ777777777º[[4-----VV6666KKK666KK66K6K6K66KK66K6K6K66KK66K6K6K66KK66K6K6K66KK66K6K6K66KK66K6K6K66KK66K6K6K66KK66K6K6K66KK66K6K6K66KK66K6K6K66KK66K6K6K66KK66K6K6K66KK66K6K6K66KK66K6K6K66KK66K6K6K66KK66K6K6K66KK66K6K6K66KK66K6K6K66KK66K6K6K66KK66K6K6K66KK66K6K6K66KK66K6K6K66KK66K6K6K66KK66K6K6K66KK66K6K6K66KK66K6K6K66KK66K6K6K66KK66K6K6K66KK66K6K6K66KK66K6K6K66KK66K6K6K66KK66K6K6K66KK66K6K6K66KK66K6K6K66KK66K6K6K66KK66K6K6K66KK66K6K6K66\n",
      "\n",
      "Epoch: 0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/keras/models.py:848: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "3138/3138 [==============================] - 83s - loss: 3.1801    \n",
      "D                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
      "\n",
      "Epoch: 1\n",
      "\n",
      "Epoch 1/1\n",
      "3138/3138 [==============================] - 84s - loss: 2.7785    \n",
      "\n",
      "o the the tor to the tor to the tor to the tor to the tor to the tor to the tor to the tor to the tor to the tor to the tor to the tor to the tor to the tor to the tor to the tor to the tor to the tor to the tor to the tor to the tor to the tor to the tor to the tor to the tor to the tor to the tor to the tor to the tor to the tor to the tor to the tor to the tor to the tor to the tor to the tor to the tor to the tor to the tor to the tor to the tor to the tor to the tor to the tor to the tor t\n",
      "\n",
      "Epoch: 2\n",
      "\n",
      "Epoch 1/1\n",
      "3138/3138 [==============================] - 82s - loss: 2.3754    \n",
      "é the Commiss of the Commiss of the Commiss of the Commiss of the Commiss of the Commiss of the Commiss of the Commiss of the Commiss of the Commiss of the Commiss of the Commiss of the Commiss of the Commiss of the Commiss of the Commiss of the Commiss of the Commiss of the Commiss of the Commiss of the Commiss of the Commiss of the Commiss of the Commiss of the Commiss of the Commiss of the Commiss of the Commiss of the Commiss of the Commiss of the Commiss of the Commiss of the Commiss of the\n",
      "\n",
      "Epoch: 3\n",
      "\n",
      "Epoch 1/1\n",
      "3138/3138 [==============================] - 79s - loss: 2.1376    \n",
      "3 the Commission the Commission the Commission the Commission the Commission the Commission the Commission the Commission the Commission the Commission the Commission the Commission the Commission the Commission the Commission the Commission the Commission the Commission the Commission the Commission the Commission the Commission the Commission the Commission the Commission the Commission the Commission the Commission the Commission the Commission the Commission the Commission the Commission the\n",
      "\n",
      "Epoch: 4\n",
      "\n",
      "Epoch 1/1\n",
      "3138/3138 [==============================] - 79s - loss: 1.9576    \n",
      "y the report the proprammen and the report the porticial of the report the porticis of the report the porticial of the report the porticis of the report the porticial of the report the porticis of the report the porticial of the report the porticis of the report the porticial of the report the porticis of the report the porticial of the report the porticis of the report the porticial of the report the porticis of the report the porticial of the report the porticis of the report the porticial of \n",
      "\n",
      "Epoch: 5\n",
      "\n",
      "Epoch 1/1\n",
      "3138/3138 [==============================] - 79s - loss: 1.8034    \n",
      "on the Commission the Commission the Commission the Commission the Commission the Commission the Commission the Commission the Commission the Commission the Commission the Commission the Commission the Commission the Commission the Commission the Commission the Commission the Commission the Commission the Commission the Commission the Commission the Commission the Commission the Commission the Commission the Commission the Commission the Commission the Commission the Commission the Commission th\n",
      "\n",
      "Epoch: 6\n",
      "\n",
      "Epoch 1/1\n",
      "3138/3138 [==============================] - 81s - loss: 1.6722    \n",
      ".\n",
      "The regions of the regions of the regions of the regions of the regions of the regions of the regions of the regions of the regions of the regions of the regions of the regions of the regions of the regions of the regions of the regions of the regions of the regions of the regions of the regions of the regions of the regions of the regions of the regions of the regions of the regions of the regions of the regions of the regions of the regions of the regions of the regions of the regions of the\n",
      "\n",
      "Epoch: 7\n",
      "\n",
      "Epoch 1/1\n",
      "3138/3138 [==============================] - 85s - loss: 1.5600    \n",
      "?\n",
      "The Commission in the Commission in the Commission in the Commission in the Commission in the Commission in the Commission in the Commission in the Commission in the Commission in the Commission in the Commission in the Commission in the Commission in the Commission in the Commission in the Commission in the Commission in the Commission in the Commission in the Commission in the Commission in the Commission in the Commission in the Commission in the Commission in the Commission in the Commissi\n",
      "\n",
      "Epoch: 8\n",
      "\n",
      "Epoch 1/1\n",
      "3138/3138 [==============================] - 98s - loss: 1.4607    \n",
      "[ the Commission is the Commission is the Commission is the Commission is the Commission is the Commission is the Commission is the Commission is the Commission is the Commission is the Commission is the Commission is the Commission is the Commission is the Commission is the Commission is the Commission is the Commission is the Commission is the Commission is the Commission is the Commission is the Commission is the Commission is the Commission is the Commission is the Commission is the Commissi\n",
      "\n",
      "Epoch: 9\n",
      "\n",
      "Epoch 1/1\n",
      "3138/3138 [==============================] - 94s - loss: 1.3739    \n",
      "; the concerned of the structural policy on the structural policy on the structural policy on the structural policy on the structural policy on the structural policy on the structural policy on the structural policy on the structural policy on the structural policy on the structural policy on the structural policy on the structural policy on the structural policy on the structural policy on the structural policy on the structural policy on the structural policy on the structural policy on the st\n",
      "\n",
      "Epoch: 10\n",
      "\n",
      "Epoch 1/1\n",
      "3138/3138 [==============================] - 89s - loss: 1.2972    \n",
      "port of the Commission and programme and regions and the Commission and programme and regions and the Commission and programme and regions and the Commission and programme and regions and the Commission and programme and regions and the Commission and programme and regions and the Commission and programme and regions and the Commission and programme and regions and the Commission and programme and regions and the Commission and programme and regions and the Commission and programme and regions a\n",
      "\n",
      "Epoch: 11\n",
      "\n",
      "Epoch 1/1\n",
      "3138/3138 [==============================] - 80s - loss: 1.2252    \n",
      "[Commission is the first consider to the first comments of the regions and the report on the regions and the report on the regions and the report on the regions and the report on the regions and the report on the regions and the report on the regions and the report on the regions and the report on the regions and the report on the regions and the report on the regions and the report on the regions and the report on the regions and the report on the regions and the report on the regions and the r\n",
      "\n",
      "Epoch: 12\n",
      "\n",
      "Epoch 1/1\n",
      "3138/3138 [==============================] - 80s - loss: 1.1615    \n",
      "änd to the Commission and the Commission and the Commission and the Commission and the Commission and the Commission and the Commission and the Commission and the Commission and the Commission and the Commission and the Commission and the Commission and the Commission and the Commission and the Commission and the Commission and the Commission and the Commission and the Commission and the Commission and the Commission and the Commission and the Commission and the Commission and the Commission and\n",
      "\n",
      "Epoch: 13\n",
      "\n",
      "Epoch 1/1\n",
      "3138/3138 [==============================] - 80s - loss: 1.0979    \n",
      "and to the entremely in the position of the European Parliament and the requirements of the European Parliament and the Commission and the Commission and the Commission and the Commission and the Commission and the Commission and the Commission and the Commission and the Commission and the Commission and the Commission and the Commission and the Commission and the Commission and the Commission and the Commission and the Commission and the Commission and the Commission and the Commission and the \n",
      "\n",
      "Epoch: 14\n",
      "\n",
      "Epoch 1/1\n",
      "3138/3138 [==============================] - 83s - loss: 1.0371    \n",
      "zent in the fact that the Commissioner proposals for expertent the regions and the Commission and programme for the Committee on Economic and Monetary Affairs, the Committee on Economic and Monetary Affairs, the Committee on Economic and Monetary Affairs, the Committee on Economic and Monetary Affairs, the Committee on Economic and Monetary Affairs, the Committee on Economic and Monetary Affairs, the Committee on Economic and Monetary Affairs, the Committee on Economic and Monetary Affairs, the \n",
      "\n",
      "Epoch: 15\n",
      "\n",
      "Epoch 1/1\n",
      "2250/3138 [====================>.........] - ETA: 23s - loss: 0.9713"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-7f35f338a174>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m33\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n\\nEpoch: {}\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0mnb_epoch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mgenerate_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGENERATE_LENGTH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVOCAB_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mix_to_char\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    865\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1596\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1598\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m     def evaluate(self, x, y,\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2273\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import csv\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM, SimpleRNN\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "\n",
    "BATCH_SIZE = 50\n",
    "HIDDEN_DIM = 500\n",
    "SEQ_LENGTH = 50\n",
    "WEIGHTS = ''\n",
    "mode = 'train'\n",
    "GENERATE_LENGTH = 500\n",
    "LAYER_NUM = 2\n",
    "\n",
    "X, y, VOCAB_SIZE, ix_to_char = load_data('assignment1-data/training.en', SEQ_LENGTH)\n",
    "model = Sequential()\n",
    "model.add(LSTM(HIDDEN_DIM, input_shape=(None, VOCAB_SIZE), return_sequences=True))\n",
    "for i in range(LAYER_NUM - 1):\n",
    "  model.add(LSTM(HIDDEN_DIM, return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(VOCAB_SIZE)))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\")\n",
    "generate_text(model, 500, VOCAB_SIZE, ix_to_char)\n",
    "if not WEIGHTS == '':\n",
    "  model.load_weights(WEIGHTS)\n",
    "  nb_epoch = int(WEIGHTS[WEIGHTS.rfind('_') + 1:WEIGHTS.find('.')])\n",
    "else:\n",
    "  nb_epoch = 0\n",
    "if mode == 'train' or WEIGHTS == '':\n",
    "  while nb_epoch<33:\n",
    "    print('\\n\\nEpoch: {}\\n'.format(nb_epoch))\n",
    "    model.fit(X, y, batch_size=BATCH_SIZE, verbose=1, nb_epoch=1)\n",
    "    nb_epoch += 1\n",
    "    generate_text(model, GENERATE_LENGTH, VOCAB_SIZE, ix_to_char)\n",
    "    if nb_epoch % 10 == 0:\n",
    "      model.save_weights('checkpoint_layer_{}_hidden_{}_epoch_{}.hdf5'.format(LAYER_NUM, HIDDEN_DIM, nb_epoch))\n",
    "\n",
    "elif WEIGHTS == '':\n",
    "  model.load_weights(WEIGHTS)\n",
    "  generate_text(model, GENERATE_LENGTH, VOCAB_SIZE, ix_to_char)\n",
    "  print('\\n\\n')\n",
    "else:\n",
    "  print('\\n\\nNothing to do!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------\u001b[0m",
      "\u001b[0;31mSystemExit\u001b[0m       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-36a02c7dde68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_argument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-mode'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_argument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-weights'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mDATA_DIR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data_dir'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/argparse.py\u001b[0m in \u001b[0;36mparse_args\u001b[0;34m(self, args, namespace)\u001b[0m\n\u001b[1;32m   1731\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1732\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'unrecognized arguments: %s'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1733\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1734\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/argparse.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, message)\u001b[0m\n\u001b[1;32m   2387\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2388\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'prog'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'message'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2389\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%(prog)s: error: %(message)s\\n'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda/lib/python3.6/argparse.py\u001b[0m in \u001b[0;36mexit\u001b[0;34m(self, status, message)\u001b[0m\n\u001b[1;32m   2374\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2375\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_print_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2376\u001b[0;31m         \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2378\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSystemExit\u001b[0m: 2"
     ]
    }
   ],
   "source": [
    "%tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def perplexity(lines, model=''):\n",
    "    doc_length = 0\n",
    "    total_log_sum = 0\n",
    "    line_perplexities = []\n",
    "    for line in lines:\n",
    "        line_perplexity = 0\n",
    "        for char_index in range(len(line) - 2):\n",
    "#             print(ord(line[char_index]))\n",
    "            probability = tri_gram_add_one[getasciiForSingleChar(line[char_index])][getasciiForSingleChar(line[char_index+1])][getasciiForSingleChar(line[char_index+2])]\n",
    "            if probability > 0:\n",
    "                probability = np.log2(probability)\n",
    "            line_perplexity += probability\n",
    "        line_perplexities.append(line_perplexity)\n",
    "        doc_length += len(line)\n",
    "    for line_perplexity in line_perplexities:\n",
    "        total_log_sum += line_perplexity\n",
    "    perplexity = 2 ** -((1/(total_log_sum-2))*doc_length)\n",
    "    print(perplexity)\n",
    "    \n",
    "    \n",
    "\n",
    "#     perplexity = 2 ** -((1/(sum3-2))*sum2)\n",
    "#     print perplexity\n",
    "#     return perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1735456014\n"
     ]
    }
   ],
   "source": [
    "processed_test_lines = []\n",
    "list = readFile(\"test\")\n",
    "for l in list:\n",
    "    for line in l:\n",
    "        processed_test_lines.append(process_line(line))\n",
    "perplexity(processed_test_lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
